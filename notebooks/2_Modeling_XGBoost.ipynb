{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and setting up varibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = str(Path().resolve().parents[0])\n",
    "dotenv_path = os.path.join(project_dir, '.env')\n",
    "env_var = dotenv.load_dotenv(dotenv_path)\n",
    "processed_data_path = os.environ.get(\"PROCESSED_DATA_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(project_dir, processed_data_path, \"train.csv\"), index_col=\"PassengerId\")\n",
    "x_data = train.drop(columns=[\"Transported\"])\n",
    "y_data = train[\"Transported\"].astype(\"bool\")\n",
    "data_dmatrix = xgb.DMatrix(data=x_data,label=y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try first XGBoost model with standarts parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size=0.2)\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:logistic',\n",
    "                          colsample_bytree = 0.3,\n",
    "                          learning_rate = 0.1,\n",
    "                          max_depth = 10,\n",
    "                          alpha = 10,\n",
    "                          n_estimators = 10,\n",
    "                          tree_method='gpu_hist',\n",
    "                          gpu_id=0)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "preds = xg_reg.predict(X_test)\n",
    "preds[preds > 0.5] = 1\n",
    "preds[preds <= 0.5] = 0\n",
    "accuracy_score(y_test, preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a basic folding of the dataset and do a 50-folding run to evaluate the previous model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=50, shuffle=True, random_state=7)\n",
    "\n",
    "results = []\n",
    "for train_ix, test_ix in  kfold.split(np.array(x_data), np.array(y_data)):\n",
    "    train_X, test_X = np.array(x_data)[train_ix], np.array(x_data)[test_ix]\n",
    "    train_y, test_y = np.array(y_data)[train_ix], np.array(y_data)[test_ix]\n",
    "\n",
    "    \n",
    "    xg_reg.fit(train_X,train_y)\n",
    "    preds = xg_reg.predict(test_X)\n",
    "    preds[preds > 0.5] = 1\n",
    "    preds[preds <= 0.5] = 0\n",
    "    accuracy = accuracy_score(test_y, preds)\n",
    "    results.append(accuracy)\n",
    "    print(f\"For this run, acurracy is {accuracy*100:.2f}%\")\n",
    "    \n",
    "print(f'Average accuracy is {np.mean(results)*100:.2f}% ({np.std(results):.2f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a similar folding from the previous cell, but using functios of the XGBoost itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\":\"binary:logistic\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=3,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=\"error\", as_pandas=True, seed=123)\n",
    "\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a grid search to find the best parameters for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xg_reg = xgb.XGBClassifier(objective ='binary:logistic',\n",
    "                                colsample_bytree = 0.55,\n",
    "                                learning_rate=0.1,\n",
    "                                tree_method='gpu_hist',\n",
    "                                gpu_id=0)\n",
    "\n",
    "params = [{\n",
    "          'n_estimators': [10, 100, 200],\n",
    "          'max_depth': [10,15,20],\n",
    "          'alpha': [0,5,10,15],\n",
    "          'reg_lambda': [0.5,1,1.5]      \n",
    "          }]\n",
    "\n",
    "xg_grid = GridSearchCV(estimator=grid_xg_reg, scoring='accuracy', param_grid=params, cv=5, verbose=2)\n",
    "\n",
    "xg_grid.fit(X_train, y_train)\n",
    "\n",
    "print(xg_grid.best_params_)\n",
    "\n",
    "print(xg_grid.score(X_train, y_train))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9257dd191ad9f063dbb6f097a25b9e58855f0e11f4ad184d2bdaae0b3e54e185"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('Spaceship_Titanic')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
